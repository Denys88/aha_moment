# RTX 5090 (32 GB) â€” uses nearly all VRAM
model:
  name: "unsloth/Qwen2.5-3B"
  max_seq_len: 1024
  lora_rank: 64
  load_in_4bit: true
  use_vllm: true
  gpu_memory_utilization: 0.6

training:
  max_steps: 1000
  learning_rate: 5e-6
  num_generations: 8
  gradient_accumulation_steps: 4
  max_completion_length: 512
  max_prompt_length: 256
  save_steps: 100
  output_dir: "outputs_pretrained"

sampling:
  print_every: 20
  num_samples: 3
